### 조건 필터링
- indexing
- slicing
- loc (조건필터)
### iloc (integer location): 
loc(location)만 유사하지만, index만 허용(숫자로만 접근)
- indexing: `.iloc[1, 3]` 좌표로 값 불러올 수 있음(값 1개만 표시)
- Fancy Indexing:
`df.iloc[[0, 3, 4], [0, 1, 5, 6]]` (행/열의 index 표시)
 0, 3, 4행의 0, 1, 5, 6열을 가져옴
- Slicing:
`df.iloc[:3, :5]` 0~2번째 행, 0~4번째 열까지를 가져옴
- at :loc와 동일하지만 속도가 빠름 - 하나의 인덱스만 가져옴
- iat :iloc으로 대체가능 하나의 인덱스만 가져옴
- where: python dictionary의 get과 유사
`DataFrame.where(조건(T/F), 아닐경우 할당 값- 기본값 Nan)`
`df['fare'].where(df['fare'] < 20, 0).tail(10)`

- isin :특정 값의 포함여부
```python
sample = pd.DataFrame({'name': ['kim', 'lee', 'park', 'choi'], 
                        'age': [24, 27, 34, 19]
                      })
sample
sample['name'].isin(['kim', 'lee'])
(컨디션으로 적용 T/F)
# 0     True
# 1     True
# 2    False
# 3    False
# Name: name, dtype: bool
```
```예제

```

## 통계
- describe(): 요약통계
전반적인 주요통계를 확인할 수 있음

수치형 컬럼에 대한 통계표를 보여줌
- count(): 데이터의 개수 `.count()` 데이터 전체의 갯수나 단일 column의 갯수를 구할 수 있음
- mean(): 데이터의 평균,
str이 섞여있는 데이터셋의 경우 `df.mean(numeric_only=True)`로 옵션 걸어줘야함
전체 데이터셋이나, 컬럼에 대한 평균, 조건별 평균을 구할 수 있음

> `skipna=True` 옵션
기술 통계 함수에서는 `skipna=True`가 기본으로 설정되어있음, 
`skipna=False`로 설정하는경우 NaN 값이 있는 column은 NaN으로 출력
- median() : 중앙값을 출력
데이터를 오름차순 정렬하여 중앙에 위치한 값.
이상치(outlier- 범위가 많이 벗어나는 값)가 존재하는 경우, mean()보다 median()을 대표값으로 더 선호
짝수개의 데이터가 있는 경우 가운데 2개 중앙데이터의 평균값을 출력
- sum() 합계
- cumsum() 누적합
- cumprod() 누적곱

### var() - 분산
 ```python
my_var = ((df['fare'].values - fare_mean) ** 2).sum() / (df['fare'].count() - 1)
my_var
```
- `df['fare'].var()`

### std() - 표준편차
- `df['fare'].std()`
- 분산 ** 0.5
- 분산의 제곱근
- 평균치를 기준으로 데이터들의 표준적인 차이를 구함
### min(), max()
- 최솟값과 최댓값

### aggregation: 통합 통계 적용 (복수의 통계 함수 적용)
- `df['age'].agg(['min', 'max', 'count', 'mean'])`
- 보고 싶은 통계 함수를 적용해서 보여줌
### quantile() 분위
- 주어진 데이터를 동등한 크기로 분할하는 지점을 말함
- 하위부터 0~1까지의 소수로 대입
- `df['age'].quantile(0.1)`

### unique() - 고유값, nunique() - 고유값 개수
- unique(): 각 column에 해당하는 고유값을 구함
- nunique(): 각 column에 해당하는 고유값의 갯수를 구함

### mode() - 최빈값
- 가장 많이 출현한 데이터를 구함
```python
df['who'].mode()
# 0    man
# Name: who, dtype: object

df['deck'].mode()
# 0    C
# Name: deck, dtype: category
# Categories (7, object): ['A', 'B', 'C', 'D', 'E', 'F', 'G']
```
### corr() - 상관관계
- 컬럼별로 상관관계를 확인할 수 있음
- `df.corr(numeric_only=True)`
- **-1~1 사이의 범위**를 가집니다.
- **-1에 가까울 수록 반비례** 관계, **1에 가까울수록 정비례** 관계를 의미합니다.

## 결측치
- `copy()` : 데이터 프레임을 복제함. 복제한 데이터프레임을 수정해도 원본에는 영향을 미치지 않음
- 결측치 처리를 위해 필요
### 결측치
- 비어있는 데이터로 이에 대한 처리는 매우 중요
- 처리 방법
    - 결측 데이터 확인
    - 결측치가 아닌 데이터 확인
    - 결측 데이터 채우기
    - 결측 데이터 제거하기
1. 결측 데이터 확인 - isnull(), isnan()
    - 결측치 갯수를 확인하기 위해 `df.isnull().sum()` 혹은 `df.isnan().sum()`으로 확인
    - DataFrame 전체 결측 데이터의 갯수를 합산하기 위해서는 sum()을 두 번 사용하면 됨`df.isnull().sum().sum()`
2. 결측치가 아닌 데이터 확인 - `notnull()`
    - 결측 데이터 필터링:
    isnull() 함수가 결측 데이터를 찾는 boolean index 입니다.
    loc에 적용하여 조건 필터링 걸 수 있음
    `df.loc[df['age'].isnull()]`
3. 결측치 채우기 - `fillna()`
    - 카테고리형에서 없는 카테고리로 채워주고자 할 때는 먼저 `add_categories`로 카테고리 추가 후 채워야 함
    - ex) `df1['deck'].cat.add_categories('No Data').fillna('No Data')`
- 통계값으로 채우기
    `df1['age'].fillna(df1['age'].mean()).tail()`
    - fillna(통계값)으로

- 최빈값으로 채우기
    - `df1['deck'].mode()[0]`를 fillna에 넣음
    - 최빈값은 항상 0번째 index 지정하여 값을 추출한 후 채워야 함
- NaN 값이 있는 데이터 제거하기 (dropna)
    - `df1.dropna()`로 1개라도 NaN이 있는 행을 제거
    - 기본 옵션 값은 `how=any`로 설정되어 있으며, 다음과 같이 변경할 수 있습니다.
        - any: 1개의 column 이라도 
        NaN값이 존재시 drop
        - all: 모든 column값이 NaN일때 해당 
        행을 지움
## 전처리 추가 삭제 데이터변환
### 추가
- 임의의 값을 대입하여 새로운 컬럼을 추가할 수 있음
`df1['새로운컬럼명'] = 임의값`

### 삭제
1. 행삭제
    - 행삭제시 index를 지정하여 삭제 `df.drop(1)`
    - 범위지정`df1.drop(np.arange(10))`
    -  fancy indexing
    `df1.drop([1, 3, 5, 7, 9])`
2. 열삭제
    - 열삭제시 반드시 `axiws=1`옵션을 지정해야함
    - `df1.drop('class', axis=1).head()` 
    - 다수의 column 삭제`df1.drop(['who', 'deck', 'alive'], axis=1)`
    - 수정 내용을 적용하려면 덮어씌우기 할당 하거나 `inplace=True`옵션을 지정해야함
    `df1.drop(['who', 'deck', 'alive'], axis=1, inplace=True)`

3. 컬럼간 연산
    - 숫자 데이터의 경우 연산 가능 :     
    `df1['family'] = df1['sibsp'] + df1['parch']`
    - 문자열의 경우 합(이어붙이기) 가능:    
    `df1['gender'] = df1['who'] + '-' + df1['sex']`
    - `round()`를 이용하여 소수점 자리수를 지정할 수 있다.
- * 연산시 1개의 column이라도 NaN값을 포함하면 결과가 NaN이 됨
### 타입변환 (astype)
- pclass의 타입을 int32로: `df1['pclass'].astype('int32').head()`
- pclass의 타입을 float로: `df1['pclass'].astype('float32').head()`
- pclass의 타입을 object로: `df1['pclass'].astype('str').head()`
#### Category로 변환
- 값에 범위가 있거나, 유한한 수치가 정해져있다면 category로 사용하는 것이 좋을 수 있다
`df1['who'].astype('category').head()`
- category로 변환했다면 .cat으로 접근하여 category의 attribute를 사용할 수 있음
`df1['who'].cat.codes` - 카테고리의 인덱스로 출력 - 컴퓨터가 이해하기 쉬움
- 카테고리 이름을 바꾸는 법 : `df1['who'] = df1['who'].cat.rename_categories([f'Group({g})' for g in df1['who'].cat.categories])`

#### datetime - 날짜, 시간
- date_range: 주요옵션값
    - start: 시작날짜
    - end: 끝날짜
    - periods: 생성할 데이터 개수
    - freq: 주기
- Dtype: datetime64[ns]
- datetime 타입: dt.속성으로 접근 가능
    - pandas.Series.dt.year: 연도
    - pandas.Series.dt.month: 월
    - pandas.Series.dt.day: 일
    - pandas.Series.dt.hour: 시
    - pandas.Series.dt.minute: 분
    - pandas.Series.dt.second: 초
    - pandas.Series.dt.microsecond: micro 초
    - pandas.Series.dt.nanosecond: nano 초
    - pandas.Series.dt.week: 주
    - pandas.Series.dt.weekofyear: 연중 몇 째주
    - pandas.Series.dt.dayofweek: 요일
    - pandas.Series.dt.weekday: 요일 (dayofweek과 동일)
    - pandas.Series.dt.dayofyear: 연중 몇 번째 날
    - pandas.Series.dt.quarter: 분기
    - dayofweek: 요일(0:월요일, 6:일요일)

- to_dateime: 표현방식 formating
    - 날짜관련 컬럼이 object로 인식되어있을때 datetime 타입으로 변경
    `pd.to_datetime(df2['대여일자'])`   
    - 재대입하여 사용해야함

#### pd.to_numeric()
 - object나 numerical type이 아닌 칼럼을 수치형(numeric) 컬럼으로 변환할 때 사용
 `pd.to_numeric(df2['운동량'])`
 - 숫자형이 아닌 형태들이나 NaN이 들어가 있으면 변환 에러가 생김
- 이때 `errors=` 옵션 값을 바꾸어 해결할 수 있음
`errors=` 옵션 값을 바꾸어 해결할 수 있습니다.
    - errors : {'ignore', 'raise', 'coerce'}, default 'raise'
    - If 'raise', then invalid parsing will raise an exception
    - If 'coerce', then invalid parsing will be set as NaN
    - If 'ignore', then invalid parsing will return the input
- errors='coerce'로 지정하면 잘못된 문자열은 NaN 값으로 치환하여 변환
- errors='ignore'로 지정하게 되면 잘못된 문자열이 숫자로 변환이 안되고 무시하기 때문에 전체 컬럼의 dtype이 object로 그대로 남아있습니다.

#### pd.cut()- 구간나누기(binning)
```python
bins = [0, 200, 400, df2['운동량'].max()]
pd.cut(df2['운동량'], bins, right=False)
```
- 0~ 199, 200~399, 400~max 3구간으로 나눠줌
- 라벨을 지정해줄 수 있으며, 지정한 bins의 개수보다 1개가 적어야 함 `[`는 `<=`, `(` 는 `<` 
```python
labels = ['운동부족', '보통', '많음']
pd.cut(df2['운동량'], bins, labels=labels, right=False)
```
- `bins`옵션을 통해 구간의 갯수를 통해 나눌 수 있음
`df2['운동량_cut'] = pd.cut(df2['운동량'], bins=10)`

#### pd.qcut() 
- 동일한 개수를 갖도록 구간분할
- pd.cut()과 유사하지만, quantity 즉 데이터의 분포를 최대한 비슷하게 유지하는 구간을 분할 합니다.
- 범위 간격을 조정하기 위해 qcut_bins옵션을 적용가능
```python
qcut_bins = [0, 0.2, 0.8, 1]
pd.qcut(df2['운동량'], qcut_bins)
```

## group by pivottable
