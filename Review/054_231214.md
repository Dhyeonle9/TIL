# 기초 트리 모델

# 결정 트리 (Decision Tree)

### ****결정 트리 (Decision Tree)****

- 관측값과 목푯값을 연결시켜주는 예측 모델, 나무 모양으로 데이터를 분류
- `수많은 트리 기반 모델의 기본 모델(based model)`이 되는 중요 모델
- **VS 선형 모델** : 선형 모델이 각 변수에 대한 기울기값들을 최적화하여 모델을 만들어나갔다면, 트리 모델에서는 각 변수의 `특정 지점을 기준으로 데이터를 분류` 해가며 예측 모델을 만듦

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/84b5f359-abf3-4090-a2c4-631cebe6dc23/efd7c1fc-b2e7-4928-aa0f-234cb13b1af6/Untitled.png)

---

- 데이터를 무수하게 쪼개어 나가고, 각 그룹에 대한 예측치를 만들어내는 방식
- 예) 남자/여자로 나눠서 각 목표값 평균치를 나눔, 나이를 30세 이상/미만인 두 부류로 나눠서 평균치를 계산…
- 예측력과 성능은 떨어지지만 `시각화(설명력)`가 매우 뛰어남
- 다른 트리모델을 이해하기 위해 필요

---

- 종속변수가 `연속형 데이터와 범주형 데이터 모두에 사용`할 수 있음
- 모델링 `결과를 시각화할 목적`으로 가장 유용
- `아웃라이어가 문제될 정도로 많을 때 선형모델보다 좋은 대안`이 될 수 있음

---

**장점**

-` 데이터에 대한 가정이 없는 모델 (Nonparametric Model) `(VS 선형 회귀)
- `아웃라이어에 영향을 거의 받지 않음`
- 트리 그래프를 통해서 직관적으로 이해 & 설명 가능 → `시각화에 굉장히 탁월`

**단점**

- 트리가 무한정 `깊어지면 오버피팅 문제`를 야기
- `발전된 트리 기반 모델들에 비해 예측력이 상당히 떨어짐`

### ****예측력? 설명력?****

- 예측력 : 모델 학습을 통해 얼마나 `좋은 예측치`를 보여주는가
- 설명력 : 학습된 모델을 얼마나 `쉽게 해석`할 수 있는지
- 알고리즘의 `복잡도가 증가할수록 예측력은 좋아지나 설명력은 다소 떨어지는 반비례 관계`
    - 즉, 단순한 알고리즘일수록 예측력이 상대적으로 떨어질 수 있으나 해석에 용이하며, 복잡한 알고리즘은 예측력이 뛰어난만큼 해석은 어려움
- `결정트리와 회귀 분석은 상대적으로 해석이 쉬워` **설명력이 높다**고 할 수 있으며, 이후 배울 알고리즘들은 `복잡도가 증가`하여 **예측력**이 높지만 해석이 어려움. 딥러닝 또한 매우 복잡한 알고리즘으로 해석이 어려워서 이를 **블랙박스**에 비유하기도 함
- 의학계열에서 특정 질병의 발병률에 대한 예측 모델을 만들 때는, 발병률을 높이거나 억제하는 중요한 요인을 밝히는 데는 설명력이 좋은 알고리즘이 적합할 수 있고, 사기거래를 예측하는 모델에서는 요인보다는 더 정확하게 사기거래를 잡아낼 수 있어야 하므로 예측력이 높은 알고리즘이 더 적합할 수 있으므로 상황에 따라 우선시할 것이 다름

### 실습



### 혼동 행렬(Confusion Matrix)
**Confusion Matrix (혼동 행렬):**

- Confusion matrix는 주로 분류 모델의 성능을 평가하기 위한 도구입니다.
- 이것은 실제 데이터와 모델의 예측 사이의 관계를 시각화한 표입니다.
- Confusion matrix는 주로 2개의 클래스 (예: 양성과 음성)를 가진 이진 분류 문제에서 사용됩니다.
- 주요 요소로는 True Positive (TP), True Negative (TN), False Positive (FP), False Negative (FN)이 있습니다.

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/84b5f359-abf3-4090-a2c4-631cebe6dc23/fc6935ba-51fd-4793-8409-bb08e6072fba/Untitled.png)

**1종 오류 (Type 1 Error):**

- 1종 오류는 실제로는 거짓이지만 모델이 참으로 잘못 예측하는 경우입니다.
- 예를 들어, 의료 진단에서 실제로는 환자가 아닌데 환자로 오진하는 경우가 1종 오류입니다.
- 이것은 가끔 모델이 너무 예민하게 반응할 때 발생할 수 있습니다.

**2종 오류 (Type 2 Error):**

- 2종 오류는 실제로는 참이지만 모델이 거짓으로 예측하는 경우입니다.
- 의료 진단에서 실제로 환자인데 환자가 아니라고 오진하는 것이 2종 오류입니다.
- 이것은 모델이 민감하지 않을 때나 부족한 정보를 가질 때 발생할 수 있습니다.

# 랜덤 포레스트 (Random Forest)
### ****랜덤 포레스트 (Random Forest)****

- 결정 트리의 단점인 `오버피팅 문제를 완화`시켜주는 발전된 형태의 트리 모델
- 랜덤으로 생성된 무수히 많은 트리를 이용하여 예측을 하기 때문에 랜덤 포레스트라 불림

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/84b5f359-abf3-4090-a2c4-631cebe6dc23/e491edbe-7be9-43b4-a21e-b0fad90e7364/Untitled.png)

---

****앙상블 기법****

- `여러 모델(여기서는 결정 트리)을 활용하여 하나의 모델을 이루는 기법`
- 여러 모델을 만들고 `각 예측값들을 투표/평균 등으로 통합하여 더 정확한 예측`을 도모

![Untitled](https://prod-files-secure.s3.us-west-2.amazonaws.com/84b5f359-abf3-4090-a2c4-631cebe6dc23/641e7b11-dedc-4e28-a455-7765636ceee0/Untitled.png)

---

- 앙상블 기법을 사용한 트리 모델 중 가장 보편적인 방법
- `부스팅 모델에 비하면 예측력과 속도가 부족`하고 시각화 측면에서는 결정 트리보다 못 미치지만, 부스팅 모델을 이해하기 위해 꼭 알아야함
- 종속변수가 연속형 데이터/범주형 데이터인 경우 모두 사용 가능
- 아웃라이어가 문제가 되는 경우 선형모델의 좋은 대안
- `오버피팅 문제로 결정 트리를 사용하기 어려울 때 대신 사용` 가능

---

**장점**

- 결정 트리와 마찬가지로, 아웃라이어에 거의 영향을 받지 않음
- 선형/비선형 데이터에 상관없이 잘 작동

**단점**

- `학습 속도가 상대적으로 느린 편`
- 수많은 트리를 동원하기 때문에 `모델에 대한 해석이 어려움`

### 실습



### k-fold 교차 검증
**k-fold 교차 검증:**
- k-fold 교차 검증은 머신 러닝 모델의 성능을 평가하기 위한 방법 중 하나입니다.
- 이 방법은 데이터를 효과적으로 활용하여 모델을 테스트하고 평가하는 데 사용됩니다.
- k-fold 교차 검증은 다음과 같이 동작합니다:
1. 데이터 분할:
    - 먼저 사용 가능한 데이터 세트를 k개의 동일한 부분집합(또는 폴드)으로 나눕니다. 예를 들어, k=5인 경우 데이터는 5개의 폴드로 나눠집니다.
2. 모델 평가:
    - 모델 학습과 평가를 k번 반복합니다.
    - 각 반복에서 하나의 폴드는 검증 세트로 사용되고, 나머지 k-1개 폴드는 학습 세트로 사용됩니다.
3. 성능 측정:
    - 각 반복에서 모델은 검증 세트에 대한 성능을 측정하고 기록합니다.
    - 이러한 성능 지표를 평균화하여 모델의 전체 성능을 추정합니다.
4. 결과 평가:
    - k번의 평가 후에 모델의 성능 지표를 종합하여 최종 성능을 평가합니다.
    - 이렇게 하면 모델의 안정성과 일반화 능력을 더 신뢰할 수 있게 평가할 수 있습니다.

k-fold 교차 검증은 모델의 품질을 정확하게 평가하고, 과적합을 감지하는 데 도움이 되며, 데이터를 효율적으로 활용할 수 있는 장점이 있습니다.